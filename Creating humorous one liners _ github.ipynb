{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10434,
     "status": "ok",
     "timestamp": 1747353335531,
     "user": {
      "displayName": "Nikhila Gadge",
      "userId": "00129771705269168007"
     },
     "user_tz": -120
    },
    "id": "C7PgkJAIr7pJ"
   },
   "outputs": [],
   "source": [
    "from nltk import util, lm, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1747353336661,
     "user": {
      "displayName": "Nikhila Gadge",
      "userId": "00129771705269168007"
     },
     "user_tz": -120
    },
    "id": "H6r9oMn3tRc1",
    "outputId": "626f3170-a89b-44f7-cae8-090b0b3b1c34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747353339238,
     "user": {
      "displayName": "Nikhila Gadge",
      "userId": "00129771705269168007"
     },
     "user_tz": -120
    },
    "id": "TU7xJiCBtYhH"
   },
   "outputs": [],
   "source": [
    "def fetch_online_corpus():\n",
    "    \"\"\"fetches a one-liner joke corpus from the web\n",
    "\n",
    "    Returns:\n",
    "        list: list of one-liner jokes\n",
    "    \"\"\"\n",
    "    file = requests.get(\"https://raw.githubusercontent.com/CrowdTruth/Short-Text-Corpus-For-Humor-Detection/master/datasets/humorous_oneliners.pickle\")\n",
    "    content = file.text\n",
    "    content = content.split(\"\\n\")\n",
    "    content = content[1::2]\n",
    "    content = [c[2:] for c in content]\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747353341685,
     "user": {
      "displayName": "Nikhila Gadge",
      "userId": "00129771705269168007"
     },
     "user_tz": -120
    },
    "id": "evhU1y1A73Ll"
   },
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    # TODO: implement some preprocessing for the input\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11868,
     "status": "ok",
     "timestamp": 1747353355476,
     "user": {
      "displayName": "Nikhila Gadge",
      "userId": "00129771705269168007"
     },
     "user_tz": -120
    },
    "id": "Boxt38Ih7nIW",
    "outputId": "2cc936f1-7e52-40d8-af12-dcef229475f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10006\n",
      "Generated text with seed 'I': ['pull', 'a', 'pierced', 'ear', '.']\n",
      "Generated text with multiple seeds: ['<s>', 'what', 'have', 'been', 'discovered', 'that', 'his', 'chess', 'with', 'a']\n",
      "Generated text with multiple seeds: ['the', 'first', 'you', 'talking', 'to', 'the', 'dodgems.', 'he', 'must', 'have']\n",
      "Generated text with multiple seeds: ['i', \"'d\", 'ever', '!', '</s>', 'she', 'was', 'just', 'like', 'a']\n",
      "Generated text with multiple seeds: ['man', 'with', '42', 'inch', 'tv', '.', '</s>', 'the', 'banker', 'eat']\n",
      "Generated text with multiple seeds: ['was', 'asked', 'my', 'true', '!', '</s>', 'looking', 'for', 'her', 'when']\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    corpus = fetch_online_corpus()\n",
    "    corpus = [preprocess(s) for s in corpus]\n",
    "\n",
    "    # TODO: tokenize every sentence to get a list of tokenized sentences\n",
    "    # https://www.nltk.org/api/nltk.tokenize.word_tokenize.html#nltk.tokenize.word_tokenize\n",
    "    corpus = [nltk.tokenize.word_tokenize(i, language='english', preserve_line=True) for i in corpus]\n",
    "\n",
    "    # TODO: process the corpus with the padded_everygram pipeline:\n",
    "    # https://www.nltk.org/api/nltk.lm.preprocessing.html#nltk.lm.preprocessing.padded_everygram_pipeline\n",
    "    n_grams, tokens = nltk.lm.preprocessing.padded_everygram_pipeline(2, corpus)\n",
    "\n",
    "    # TODO: init a new Maximum Likelihood Estimator as model and fit it to your data:\n",
    "    # https://www.nltk.org/api/nltk.lm.models.html#nltk.lm.models.MLE\n",
    "    from nltk.lm import MLE\n",
    "    model = MLE(2)\n",
    "\n",
    "    print(len(model.vocab))\n",
    "\n",
    "    # fit the model here\n",
    "    model.fit(n_grams, tokens)\n",
    "\n",
    "    print(len(model.vocab))\n",
    "\n",
    "    # TODO: use the model.generate() function\n",
    "    # https://www.nltk.org/api/nltk.lm.api.html?highlight=languagemodel#nltk.lm.api.LanguageModel.generate\n",
    "    model.generate(num_words=5, text_seed=[\"I\"])\n",
    "    print(\"Generated text with seed 'I':\", model.generate(num_words=5, text_seed=[\"I\"]))  # Generate 5 words starting with \"I\")\n",
    "\n",
    "    # Experiment with different text_seeds write logic that keeps generating\n",
    "    random_seeds = [\"I\", \"Machine Learning\", \"Because\", \"AI\", \"Programming\"]\n",
    "    multiple_seed_model = [model.generate(num_words=10, text_seed = [seed]) for seed in random_seeds]\n",
    "    [print(f\"Generated text with multiple seeds:\", i) for i in multiple_seed_model]\n",
    "\n",
    "    # output until the end of sequence token is generated.\n",
    "\n",
    "    # Clear the output of end and start of sequence tokens\n",
    "\n",
    "    # What happens if you switch the n of your n-gram model?\n",
    "    n_grams, tokens = nltk.lm.preprocessing.padded_everygram_pipeline(5, corpus)\n",
    "    model = MLE(5)\n",
    "    model.fit(n_grams, tokens)\n",
    "\n",
    "    # Also experiment with the vocabulary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: How likely is the token \"not\" given the tokens \"I will\" acording to your model?\n",
    "    # What about \"is\" given \"the cat\"? What do you make of these probabilities?\n",
    "    # Check out other probabilities too\n",
    "    # https://www.nltk.org/api/nltk.lm.api.html?highlight=languagemodel#nltk.lm.api.LanguageModel.score\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxRBcnvB0np3"
   },
   "source": [
    "#Practice"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dxRBcnvB0np3"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
