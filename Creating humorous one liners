from nltk import util, lm, word_tokenize
import requests
import re
import nltk
nltk.download('punkt_tab')
def fetch_online_corpus():
    """fetches a one-liner joke corpus from the web

    Returns:
        list: list of one-liner jokes
    """
    file = requests.get("https://raw.githubusercontent.com/CrowdTruth/Short-Text-Corpus-For-Humor-Detection/master/datasets/humorous_oneliners.pickle")
    content = file.text
    content = content.split("\n")
    content = content[1::2]
    content = [c[2:] for c in content]
    return content

def preprocess(sentence):
    # TODO: implement some preprocessing for the input
    sentence = sentence.lower()

    return sentence

def main():
    corpus = fetch_online_corpus()
    corpus = [preprocess(s) for s in corpus]

    # TODO: tokenize every sentence to get a list of tokenized sentences
    # https://www.nltk.org/api/nltk.tokenize.word_tokenize.html#nltk.tokenize.word_tokenize
    corpus = [nltk.tokenize.word_tokenize(i, language='english', preserve_line=True) for i in corpus]

    # TODO: process the corpus with the padded_everygram pipeline:
    # https://www.nltk.org/api/nltk.lm.preprocessing.html#nltk.lm.preprocessing.padded_everygram_pipeline
    n_grams, tokens = nltk.lm.preprocessing.padded_everygram_pipeline(2, corpus)

    # TODO: init a new Maximum Likelihood Estimator as model and fit it to your data:
    # https://www.nltk.org/api/nltk.lm.models.html#nltk.lm.models.MLE
    from nltk.lm import MLE
    model = MLE(2)

    print(len(model.vocab))

    # fit the model here
    model.fit(n_grams, tokens)

    print(len(model.vocab))

    # TODO: use the model.generate() function
    # https://www.nltk.org/api/nltk.lm.api.html?highlight=languagemodel#nltk.lm.api.LanguageModel.generate
    model.generate(num_words=5, text_seed=["I"])
    print("Generated text with seed 'I':", model.generate(num_words=5, text_seed=["I"]))  # Generate 5 words starting with "I")

    # Experiment with different text_seeds write logic that keeps generating
    random_seeds = ["I", "Machine Learning", "Because", "AI", "Programming"]
    multiple_seed_model = [model.generate(num_words=10, text_seed = [seed]) for seed in random_seeds]
    [print(f"Generated text with multiple seeds:", i) for i in multiple_seed_model]

    # output until the end of sequence token is generated.

    # Clear the output of end and start of sequence tokens

    # What happens if you switch the n of your n-gram model?
    n_grams, tokens = nltk.lm.preprocessing.padded_everygram_pipeline(5, corpus)
    model = MLE(5)
    model.fit(n_grams, tokens)

    # Also experiment with the vocabulary




    # TODO: How likely is the token "not" given the tokens "I will" acording to your model?
    # What about "is" given "the cat"? What do you make of these probabilities?
    # Check out other probabilities too
    # https://www.nltk.org/api/nltk.lm.api.html?highlight=languagemodel#nltk.lm.api.LanguageModel.score

if __name__ == "__main__":
    main()
